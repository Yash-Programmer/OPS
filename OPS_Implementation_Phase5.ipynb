{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11c601d",
   "metadata": {},
   "source": [
    "# Phase 5: Visualization & Analysis\n",
    "\n",
    "**Objective:** Visualize experimental results and analyze variance reduction\n",
    "\n",
    "## Timeline: Weeks 7-8\n",
    "\n",
    "### Visualizations:\n",
    "1. Variance vs Budget curves\n",
    "2. Variance Reduction Factor (VRF) heatmaps\n",
    "3. MSE comparison with baselines\n",
    "4. Computation time analysis\n",
    "5. Algorithm comparison matrices\n",
    "\n",
    "### Analysis:\n",
    "- Statistical significance tests\n",
    "- Best algorithm by dataset/model\n",
    "- Scalability analysis (n_features impact)\n",
    "- Trade-offs: variance vs computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e781ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "project_root = Path.cwd() / 'OPS_Project'\n",
    "results_dir = project_root / 'results'\n",
    "figures_dir = results_dir / 'figures'\n",
    "figures_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"✅ Libraries loaded\")\n",
    "print(f\"Results directory: {results_dir}\")\n",
    "print(f\"Figures will be saved to: {figures_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df116d",
   "metadata": {},
   "source": [
    "## 1. Load Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Phase 4 results\n",
    "results_path = results_dir / 'experiments' / 'phase4_initial_results.csv'\n",
    "\n",
    "if results_path.exists():\n",
    "    results_df = pd.read_csv(results_path)\n",
    "    print(f\"✅ Loaded {len(results_df)} experiment results\")\n",
    "    print(f\"\\nColumns: {list(results_df.columns)}\")\n",
    "    print(f\"\\nDatasets: {results_df['dataset'].unique()}\")\n",
    "    print(f\"Algorithms: {results_df['algorithm'].unique()}\")\n",
    "    print(f\"Budgets: {sorted(results_df['budget'].unique())}\")\n",
    "    \n",
    "    display(results_df.head())\n",
    "else:\n",
    "    print(\"⚠️ Results file not found. Run Phase 4 experiments first.\")\n",
    "    results_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b0610",
   "metadata": {},
   "source": [
    "## 2. Variance vs Budget Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81208008",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    datasets = results_df['dataset'].unique()\n",
    "    \n",
    "    for idx, dataset in enumerate(datasets):\n",
    "        ax = axes[idx]\n",
    "        dataset_results = results_df[results_df['dataset'] == dataset]\n",
    "        \n",
    "        for algorithm in dataset_results['algorithm'].unique():\n",
    "            algo_results = dataset_results[dataset_results['algorithm'] == algorithm]\n",
    "            \n",
    "            budgets = algo_results['budget'].values\n",
    "            variances = algo_results['empirical_variance'].values\n",
    "            \n",
    "            ax.plot(budgets, variances, marker='o', label=algorithm.upper(), linewidth=2)\n",
    "        \n",
    "        ax.set_xlabel('Budget (L)', fontsize=10)\n",
    "        ax.set_ylabel('Variance', fontsize=10)\n",
    "        ax.set_title(f'{dataset}', fontsize=12, fontweight='bold')\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'variance_vs_budget.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✅ Saved: variance_vs_budget.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9362c5e",
   "metadata": {},
   "source": [
    "## 3. Variance Reduction Factor (VRF) Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee71734",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    # Compute VRF relative to MC\n",
    "    vrf_data = []\n",
    "    \n",
    "    for dataset in results_df['dataset'].unique():\n",
    "        dataset_results = results_df[results_df['dataset'] == dataset]\n",
    "        \n",
    "        for budget in results_df['budget'].unique():\n",
    "            budget_results = dataset_results[dataset_results['budget'] == budget]\n",
    "            \n",
    "            mc_var = budget_results[budget_results['algorithm'] == 'mc']['empirical_variance'].values\n",
    "            \n",
    "            if len(mc_var) > 0:\n",
    "                mc_var = mc_var[0]\n",
    "                \n",
    "                for algorithm in budget_results['algorithm'].unique():\n",
    "                    if algorithm != 'mc':\n",
    "                        algo_var = budget_results[budget_results['algorithm'] == algorithm]['empirical_variance'].values[0]\n",
    "                        vrf = mc_var / algo_var if algo_var > 0 else np.inf\n",
    "                        \n",
    "                        vrf_data.append({\n",
    "                            'dataset': dataset,\n",
    "                            'algorithm': algorithm.upper(),\n",
    "                            'budget': budget,\n",
    "                            'vrf': vrf\n",
    "                        })\n",
    "    \n",
    "    vrf_df = pd.DataFrame(vrf_data)\n",
    "    \n",
    "    # Create heatmap for each budget\n",
    "    budgets = sorted(results_df['budget'].unique())\n",
    "    fig, axes = plt.subplots(1, len(budgets), figsize=(20, 4))\n",
    "    \n",
    "    for idx, budget in enumerate(budgets):\n",
    "        budget_vrf = vrf_df[vrf_df['budget'] == budget]\n",
    "        pivot = budget_vrf.pivot(index='algorithm', columns='dataset', values='vrf')\n",
    "        \n",
    "        sns.heatmap(pivot, annot=True, fmt='.2f', cmap='YlOrRd', ax=axes[idx],\n",
    "                   cbar_kws={'label': 'VRF'}, vmin=1, vmax=10)\n",
    "        axes[idx].set_title(f'Budget = {budget}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('')\n",
    "        axes[idx].set_ylabel('Algorithm' if idx == 0 else '')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'vrf_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✅ Saved: vrf_heatmap.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6c52d",
   "metadata": {},
   "source": [
    "## 4. Computation Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Time vs Budget\n",
    "    for algorithm in results_df['algorithm'].unique():\n",
    "        algo_results = results_df[results_df['algorithm'] == algorithm]\n",
    "        grouped = algo_results.groupby('budget')['mean_time'].mean()\n",
    "        \n",
    "        ax1.plot(grouped.index, grouped.values * 1000, marker='o', \n",
    "                label=algorithm.upper(), linewidth=2)\n",
    "    \n",
    "    ax1.set_xlabel('Budget (L)', fontsize=11)\n",
    "    ax1.set_ylabel('Mean Time (ms)', fontsize=11)\n",
    "    ax1.set_title('Computation Time vs Budget', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Variance vs Time trade-off\n",
    "    for algorithm in results_df['algorithm'].unique():\n",
    "        algo_results = results_df[results_df['algorithm'] == algorithm]\n",
    "        \n",
    "        ax2.scatter(algo_results['mean_time'] * 1000, \n",
    "                   algo_results['empirical_variance'],\n",
    "                   label=algorithm.upper(), s=100, alpha=0.6)\n",
    "    \n",
    "    ax2.set_xlabel('Mean Time (ms)', fontsize=11)\n",
    "    ax2.set_ylabel('Empirical Variance', fontsize=11)\n",
    "    ax2.set_title('Variance-Time Trade-off', fontsize=12, fontweight='bold')\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'computation_time.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"✅ Saved: computation_time.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c2c862",
   "metadata": {},
   "source": [
    "## 5. Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ddd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Overall VRF by algorithm\n",
    "    print(\"\\nAverage Variance Reduction Factor (across all configs):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    mc_variance = results_df[results_df['algorithm'] == 'mc']['empirical_variance'].values\n",
    "    \n",
    "    for algorithm in results_df['algorithm'].unique():\n",
    "        if algorithm != 'mc':\n",
    "            algo_variance = results_df[results_df['algorithm'] == algorithm]['empirical_variance'].values\n",
    "            \n",
    "            if len(algo_variance) == len(mc_variance):\n",
    "                vrf_values = mc_variance / algo_variance\n",
    "                mean_vrf = np.mean(vrf_values)\n",
    "                std_vrf = np.std(vrf_values)\n",
    "                \n",
    "                print(f\"  {algorithm.upper():10s}: {mean_vrf:6.2f}× (±{std_vrf:.2f})\")\n",
    "    \n",
    "    # Best algorithm by budget\n",
    "    print(\"\\n\\nBest Algorithm by Budget (highest VRF):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    if vrf_df is not None:\n",
    "        for budget in sorted(vrf_df['budget'].unique()):\n",
    "            budget_vrf = vrf_df[vrf_df['budget'] == budget]\n",
    "            best = budget_vrf.loc[budget_vrf['vrf'].idxmax()]\n",
    "            print(f\"  Budget {budget:5d}: {best['algorithm']} (VRF = {best['vrf']:.2f}×)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"✅ Phase 5 Visualization Complete\")\n",
    "    print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
